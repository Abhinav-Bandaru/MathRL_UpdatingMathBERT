{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75995b3",
   "metadata": {},
   "source": [
    "# EVALUATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc8ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Top-K Indices: [149]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:   2%|â–Ž         | 1/40 [00:02<01:46,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  2\n",
      "Response:  2\n",
      "['2']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [104]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:   5%|â–Œ         | 2/40 [00:04<01:32,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  18\n",
      "Response:  18\n",
      "['18']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [109]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  \\dfrac{7}{20}\n",
      "Response:  \\frac{1}{2}\n",
      "['\\\\frac{1}{2}']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:   8%|â–Š         | 3/40 [00:10<02:29,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [159]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  10%|â–ˆ         | 4/40 [00:13<02:01,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  1.36\n",
      "Response:  \\boxed{1.36}\n",
      "['\\\\boxed{1.36}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [113]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  12%|â–ˆâ–Ž        | 5/40 [00:20<02:50,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  28\n",
      "Response:  676\n",
      "['676']\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [76]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  15%|â–ˆâ–Œ        | 6/40 [00:26<02:53,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\frac{2 \\sqrt{149}}{3}\n",
      "Response:  \\frac{2\\sqrt{149}}{3}\n",
      "['\\\\frac{2\\\\sqrt{149}}{3}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [64]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  3\\sqrt{3}\n",
      "Response:  \u0014 \frac{2bc \\, \\, \text{cos} \\frac{A}{2}}{b+c} \n",
      "\n",
      "In triangle ABC, sides are: \n",
      "AB = AC = 14, BC = 26.\n",
      "Using the Law of Cosines to find angle A:\n",
      "\n",
      "cos A = \\frac{b^2 + c^2 - a^2}{2bc} = \\frac{14^2 + 14^2 - 26^2}{2 \\times 14 \\times 14} = \\frac{196 + 196 - 676}{392} = \\frac{-284}{392} = -\\frac{71}{98}.\n",
      "\n",
      "Now, the angle A:\n",
      "A = \\arccos \\left(-\\frac{71}{98}\\right).\n",
      "\n",
      "The angle bisector from A has length:\n",
      "\n",
      "l_a = \\frac{2bc \\sin \\frac{A}{2}}{b + c}.\n",
      "\n",
      "Since b = c = 14, this simplifies to:\n",
      "\n",
      "l_a = \\frac{2 \\times 14 \\times 14 \\sin \\frac{A}{2}}{14 + 14} = \\frac{392 \\sin \\frac{A}{2}}{28} = 14 \\sin \\frac{A}{2}.\n",
      "\n",
      "Using the half-angle formula:\n",
      "\n",
      "\\sin \\frac{A}{2} = \\sqrt{\\frac{1 - \\cos A}{2}} = \\sqrt{\\frac{1 - (-\\frac{71}{98})}{2}} = \\sqrt{\\frac{1 + \\frac{71}{98}}{2}} = \\sqrt{\\frac{\\frac{98}{98} + \\frac{71}{98}}{2}} = \\sqrt{\\frac{169/98}{2}} = \\sqrt{\\frac{169}{196}} = \\frac{13}{14}.\n",
      "\n",
      "Therefore, the length of the bisector from A:\n",
      "\n",
      "l_a = 14 \\times \\frac{13}{14} = 13.\n",
      "\n",
      "Hence, the shortest angle bisector in triangle ABC is of length \\boxed{13}.}\n",
      "['\\x14 \\x0crac{2bc \\\\, \\\\, \\text{cos} \\\\frac{A}{2}}{b+c} \\n\\nIn triangle ABC, sides are: \\nAB = AC = 14, BC = 26.\\nUsing the Law of Cosines to find angle A:\\n\\ncos A = \\\\frac{b^2 + c^2 - a^2}{2bc} = \\\\frac{14^2 + 14^2 - 26^2}{2 \\\\times 14 \\\\times 14} = \\\\frac{196 + 196 - 676}{392} = \\\\frac{-284}{392} = -\\\\frac{71}{98}.\\n\\nNow, the angle A:\\nA = \\\\arccos \\\\left(-\\\\frac{71}{98}\\\\right).\\n\\nThe angle bisector from A has length:\\n\\nl_a = \\\\frac{2bc \\\\sin \\\\frac{A}{2}}{b + c}.\\n\\nSince b = c = 14, this simplifies to:\\n\\nl_a = \\\\frac{2 \\\\times 14 \\\\times 14 \\\\sin \\\\frac{A}{2}}{14 + 14} = \\\\frac{392 \\\\sin \\\\frac{A}{2}}{28} = 14 \\\\sin \\\\frac{A}{2}.\\n\\nUsing the half-angle formula:\\n\\n\\\\sin \\\\frac{A}{2} = \\\\sqrt{\\\\frac{1 - \\\\cos A}{2}} = \\\\sqrt{\\\\frac{1 - (-\\\\frac{71}{98})}{2}} = \\\\sqrt{\\\\frac{1 + \\\\frac{71}{98}}{2}} = \\\\sqrt{\\\\frac{\\\\frac{98}{98} + \\\\frac{71}{98}}{2}} = \\\\sqrt{\\\\frac{169/98}{2}} = \\\\sqrt{\\\\frac{169}{196}} = \\\\frac{13}{14}.\\n\\nTherefore, the length of the bisector from A:\\n\\nl_a = 14 \\\\times \\\\frac{13}{14} = 13.\\n\\nHence, the shortest angle bisector in triangle ABC is of length \\\\boxed{13}.}']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  18%|â–ˆâ–Š        | 7/40 [00:35<03:29,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [204]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  20%|â–ˆâ–ˆ        | 8/40 [00:38<02:52,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  10\\sqrt{2}\n",
      "Response:  10\\sqrt{2}\n",
      "['10\\\\sqrt{2}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [72]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  3\\sqrt{2}\n",
      "Response:  54\n",
      "['54']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:43<02:40,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [154]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:46<02:13,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\text{June 20}\n",
      "Response:  \\textbf{June 20\n",
      "['\\\\textbf{June 20']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [194]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:53<02:37,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  32736\n",
      "Response:  32861\n",
      "['32861']\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [151]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  735\n",
      "Response:  $ (33 \\times 21.95) + (33 \\times 2.55) = 33 \\times (21.95 + 2.55) = 33 \\times 24.50 = \\boxed{808.50}.\n",
      "['$ (33 \\\\times 21.95) + (33 \\\\times 2.55) = 33 \\\\times (21.95 + 2.55) = 33 \\\\times 24.50 = \\\\boxed{808.50}.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:57<02:16,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [33]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [01:02<02:16,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  5\n",
      "Response:  5\n",
      "['5']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [62]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [01:04<01:47,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  2\n",
      "Response:  2\n",
      "['2']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [109]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [01:12<02:06,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  5\n",
      "Response:  5\n",
      "['5']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [241]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Error making OpenAI API call: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=407, total_tokens=2455, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "False\n",
      "Error making OpenAI API call: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=407, total_tokens=2455, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "False\n",
      "Error making OpenAI API call: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=407, total_tokens=2455, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [01:57<06:54, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning text into JSON by brute force...\n",
      "Solution:  \\frac{416}{27}\n",
      "Response:  \\frac{416}{27}\n",
      "['\\\\frac{416}{27}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [192]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [02:01<05:01, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  19\n",
      "Response:  19\n",
      "['19']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [126]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [02:03<03:37,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  27\n",
      "Response:  27\n",
      "['27']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [192]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [02:06<02:44,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  50\n",
      "Response:  50\n",
      "['50']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [41]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [02:10<02:11,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\text{even}\n",
      "Response:  even\n",
      "['even']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [45]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [02:15<01:55,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\sqrt{10}\n",
      "Response:  \\sqrt{10}\n",
      "['\\\\sqrt{10}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [222]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [02:17<01:30,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  4\n",
      "Response:  4\n",
      "['4']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [229]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [02:21<01:18,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\frac{2}{3}\n",
      "Response:  \\frac{2}{3}\n",
      "['\\\\frac{2}{3}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [115]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [02:24<01:05,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  15\n",
      "Response:  15\n",
      "['15']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [123]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  336\n",
      "Response:  \\( 8 \\times 7 \\times 6 = 336 \\)\n",
      "['\\\\( 8 \\\\times 7 \\\\times 6 = 336 \\\\)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [02:27<00:55,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [5]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  \\frac{1}{5}, -\\frac{1}{3}\n",
      "Response:  -\\frac{1}{3}\n",
      "['-\\\\frac{1}{3}']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [02:32<00:58,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [16]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Error making OpenAI API call: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=387, total_tokens=2435, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "False\n",
      "Error making OpenAI API call: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=387, total_tokens=2435, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "False\n",
      "Error making OpenAI API call: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=2048, prompt_tokens=387, total_tokens=2435, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [03:05<02:48, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning text into JSON by brute force...\n",
      "Solution:  11\n",
      "Response:  11\n",
      "['11']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [112]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [03:09<02:02, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\begin{pmatrix} 8 & 12 \\\\ -4 & 20 \\end{pmatrix}\n",
      "Response:  \\\\begin{pmatrix} 8 & 12 \\\\ -4 & 20 \\\\end{pmatrix}\n",
      "['\\\\\\\\begin{pmatrix} 8 & 12 \\\\\\\\ -4 & 20 \\\\\\\\end{pmatrix}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [229]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [03:13<01:32,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  11\n",
      "Response:  12\n",
      "['12']\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [79]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [03:16<01:07,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  0\n",
      "Response:  0\n",
      "['0']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [243]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [03:19<00:49,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  4\n",
      "Response:  4\n",
      "['4']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [33]\n",
      "[INFO] Launching 1 parallel inference tasks...\n",
      "Solution:  18\\text{ ways.}\n",
      "Response:  $12$\n",
      "['$12$']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [03:22<00:38,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ðŸ” Top-K Indices: [97]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [03:24<00:28,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  9\n",
      "Response:  9\n",
      "['9']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [36]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [03:27<00:21,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  \\frac{i}{5}\n",
      "Response:  z = \\frac{i}{5}\n",
      "['z = \\\\frac{i}{5}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [48]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [03:30<00:16,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  90\n",
      "Response:  90\n",
      "['90']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [41]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [03:33<00:12,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  y^4-2y^3+7y^2+y-5\n",
      "Response:  $y^4 - 2y^3 + 7y^2 + y - 5$\n",
      "['$y^4 - 2y^3 + 7y^2 + y - 5$']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [166]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [03:35<00:08,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  120\n",
      "Response:  \\boxed{120}\n",
      "['\\\\boxed{120}']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [33]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [03:37<00:05,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  20\n",
      "Response:  20\n",
      "['20']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [26]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [03:40<00:02,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  400\n",
      "Response:  400\n",
      "['400']\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [96]\n",
      "[INFO] Launching 1 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [03:42<00:00,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:  2\n",
      "Response:  2\n",
      "['2']\n",
      "1.0\n",
      "\n",
      "ðŸ“Š  Baseline accuracy on MATH500: 75.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0.  Imports & config â€“ nothing here should clash with yours\n",
    "# ------------------------------------------------------------\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from mathbert_encoder import MathBERTEncoder\n",
    "import retriever_cosine as rc\n",
    "# from import retrieve_top_k_cosine, retrieve_sample_k_cosine\n",
    "from response_sampler import sample_responses_per_demo\n",
    "from reward_aggregator import compute_demo_accuracy\n",
    "from icl_model_wrapper import OpenAIICLModel, OpenAIAdvanced\n",
    "from grpo_optimizer import grpo_step\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import helpers\n",
    "\n",
    "reload(rc)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "K       = 1             # demos per query\n",
    "NUM_SAMPLES = 1           # model completions per query\n",
    "TEMPERATURE = 0.7           # keep same as training loop\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.  Initialise encoder **in eval mode** (weights frozen)\n",
    "# ------------------------------------------------------------\n",
    "encoder = MathBERTEncoder(device=DEVICE, trainable=False)\n",
    "encoder.eval()                                   # no grads!\n",
    "\n",
    "icl_model = OpenAIAdvanced(api_key=API_KEY,\n",
    "                           model_name=\"gpt-4.1-nano\",\n",
    "                           temperature=TEMPERATURE)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.  Load/define the inference set\n",
    "#     If you already saved a slice elsewhere, just load it.\n",
    "# ------------------------------------------------------------\n",
    "train_path = \"./data/MATH/train.jsonl\"\n",
    "train_ds_list = helpers.load_jsonl(train_path)[:40]\n",
    "raw_demos = helpers.load_jsonl(train_path)[:256]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3.  Evaluation loop\n",
    "# ------------------------------------------------------------\n",
    "total, correct = 0, 0\n",
    "all_losses     = []          # optional â€“ to compare prompt quality\n",
    "\n",
    "# Build demo pool (everything except current query)\n",
    "\n",
    "for idx in tqdm(range(len(train_ds_list)), desc=\"Baseline eval\"):\n",
    "    item       = train_ds_list[idx]\n",
    "    Q_inf, A_gt, A_ans = item[\"problem\"], item[\"solution\"], item[\"answer\"]\n",
    "    demos = [(d[\"problem\"], d[\"solution\"], d[\"answer\"])\n",
    "                for j, d in enumerate(raw_demos) if j != idx]\n",
    "        \n",
    "    # Encode query + candidate demos\n",
    "    with torch.no_grad():\n",
    "        q_emb     = encoder.encode([Q_inf], detach=True).squeeze(0)\n",
    "        demo_embs = encoder.encode([q for (q,_, _) in demos], detach=True)\n",
    "\n",
    "    # ------- ORIGINAL cosine retrieval -------------------------\n",
    "    top_k, _ = rc.retrieve_top_k_cosine(\n",
    "        q_emb, demo_embs, k=min(K, len(demos))\n",
    "    )\n",
    "    print(f\"ðŸ” Top-K Indices: {top_k}\")\n",
    "    selected_demos = [demos[i] for i in top_k]          # length = 2\n",
    "\n",
    "    # ------- Run the ICL model --------------------------------\n",
    "    responses_nested = sample_responses_per_demo(\n",
    "        demo_tuples = selected_demos,\n",
    "        Q_inf       = Q_inf,\n",
    "        icl_model   = icl_model,\n",
    "        num_samples = NUM_SAMPLES,\n",
    "        parallel=True\n",
    "    )\n",
    "    flat_responses = [r for demo_resps in responses_nested for r in demo_resps]\n",
    "    print(\"Solution: \", A_ans)\n",
    "    print(\"Response: \", flat_responses[0])\n",
    "    acc = compute_demo_accuracy(flat_responses, A_ans)\n",
    "    print(acc) \n",
    "    correct += acc\n",
    "    total   += 1\n",
    "\n",
    "baseline_acc = correct / total\n",
    "print(f\"\\nðŸ“Š  Baseline accuracy on MATH500: {baseline_acc:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551e50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem': 'How many vertical asymptotes does the graph of $y=\\\\frac{2}{x^2+x-6}$ have?', 'solution': 'The denominator of the rational function factors into $x^2+x-6=(x-2)(x+3)$. Since the numerator is always nonzero, there is a vertical asymptote whenever the denominator is $0$, which occurs for $x = 2$ and $x = -3$.  Therefore, the graph has $\\\\boxed{2}$ vertical asymptotes.', 'answer': '2', 'subject': 'Algebra', 'level': 3, 'unique_id': 'test/algebra/1.json'}\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "train_path = \"./data/MATH/train.jsonl\"\n",
    "train_ds_list = helpers.load_jsonl(train_path)\n",
    "print(train_ds_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6327e",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe73d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Step 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Examples:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f0212547e90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/josephL/miniconda3/envs/unsloth/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 23.59 GiB of which 3.94 MiB is free. Process 2894398 has 21.09 GiB memory in use. Including non-PyTorch memory, this process has 2.29 GiB memory in use. Of the allocated memory 1.92 GiB is allocated by PyTorch, and 67.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     68\u001b[39m demo_pool = [d \u001b[38;5;28;01mfor\u001b[39;00m j, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(raw_demos) \u001b[38;5;28;01mif\u001b[39;00m j != idx]\n\u001b[32m     69\u001b[39m demo_questions = [d[\u001b[33m\"\u001b[39m\u001b[33mproblem\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m demo_pool]\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m demo_embs = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatched_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_questions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m top_k_inds, sims = rc.retrieve_top_k_cosine(q_emb, demo_embs, k=\u001b[38;5;28mmin\u001b[39m(K, \u001b[38;5;28mlen\u001b[39m(demo_questions)))\n\u001b[32m     73\u001b[39m top_k_inds_adj = [i \u001b[38;5;28;01mif\u001b[39;00m i < idx \u001b[38;5;28;01melse\u001b[39;00m i + \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_k_inds]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathRL_UpdatingMathBERT/mathbert_encoder.py:128\u001b[39m, in \u001b[36mMathBERTEncoder.batched_encode\u001b[39m\u001b[34m(self, texts, batch_size, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size):\n\u001b[32m    127\u001b[39m     batch = texts[i:i+batch_size]\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     embs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.cpu()  \u001b[38;5;66;03m# â† move to CPU\u001b[39;00m\n\u001b[32m    129\u001b[39m     all_embeddings.append(embs)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(all_embeddings, dim=\u001b[32m0\u001b[39m).to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathRL_UpdatingMathBERT/mathbert_encoder.py:78\u001b[39m, in \u001b[36mMathBERTEncoder.encode\u001b[39m\u001b[34m(self, texts, max_length, detach, normalize)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03mEncode a list of texts into MathBERT embeddings.\u001b[39;00m\n\u001b[32m     61\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m \u001b[33;03m    Tensor: shape (batch_size, hidden_size)\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     70\u001b[39m encoded_input = \u001b[38;5;28mself\u001b[39m.tokenizer(\n\u001b[32m     71\u001b[39m     texts,\n\u001b[32m     72\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m     return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     76\u001b[39m ).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m hidden_states = output.last_hidden_state  \u001b[38;5;66;03m# (batch_size, seq_len, hidden_size)\u001b[39;00m\n\u001b[32m     80\u001b[39m cls_embeddings = hidden_states[:, \u001b[32m0\u001b[39m, :]   \u001b[38;5;66;03m# (batch_size, hidden_size)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1140\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1142\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1155\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    684\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    685\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    686\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         output_attentions,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    574\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    575\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m    583\u001b[39m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[32m    584\u001b[39m     self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    592\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    594\u001b[39m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:524\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    507\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    514\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m    515\u001b[39m     self_outputs = \u001b[38;5;28mself\u001b[39m.self(\n\u001b[32m    516\u001b[39m         hidden_states,\n\u001b[32m    517\u001b[39m         attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    522\u001b[39m         output_attentions,\n\u001b[32m    523\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[32m    526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:466\u001b[39m, in \u001b[36mBertSelfOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n\u001b[32m    468\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 23.59 GiB of which 3.94 MiB is free. Process 2894398 has 21.09 GiB memory in use. Including non-PyTorch memory, this process has 2.29 GiB memory in use. Of the allocated memory 1.92 GiB is allocated by PyTorch, and 67.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import helpers\n",
    "from mathbert_encoder import MathBERTEncoder\n",
    "import retriever_cosine as rc\n",
    "# from import retrieve_top_k_cosine, retrieve_sample_k_cosine\n",
    "from response_sampler import sample_responses_per_demo\n",
    "from reward_aggregator import compute_demo_accuracy\n",
    "from icl_model_wrapper import OpenAIICLModel, OpenAIAdvanced\n",
    "from grpo_optimizer import grpo_step\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "\n",
    "reload(rc)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# === Settings ===\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "K = 10\n",
    "NUM_SAMPLES_PER_DEMO = 4\n",
    "LEARNING_RATE =  5e-5\n",
    "MAX_STEPS = 15\n",
    "TEMPERATURE = 0.1\n",
    "\n",
    "# === Init ===\n",
    "encoder = MathBERTEncoder(device=DEVICE, trainable=True)\n",
    "encoder.train()\n",
    "\n",
    "icl_model = OpenAIAdvanced(api_key=API_KEY,\n",
    "                           model_name=\"gpt-4.1-nano\",\n",
    "                           temperature=TEMPERATURE)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n",
    "WARMUP_STEPS = 3 # Define number of warmup steps for the scheduler\n",
    "\n",
    "# Initialize the Learning Rate Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=MAX_STEPS\n",
    ")\n",
    "train_path = \"./data/MATH/train.jsonl\"\n",
    "all_examples = helpers.load_jsonl(train_path)\n",
    "train_ds_list = all_examples[:20]\n",
    "raw_demos = all_examples[:128]\n",
    "\n",
    "# === Training Loop ===\n",
    "reward_history = []\n",
    "N = len(train_ds_list)\n",
    "active_indices = list(range(N))\n",
    "\n",
    "for step in range(MAX_STEPS):\n",
    "    print(f\"\\n=== Training Step {step+1} ===\")\n",
    "    epoch_rewards = [None] * N                # default to None for every example\n",
    "    next_active = []\n",
    "\n",
    "    # loop only over the â€œhardâ€ examples\n",
    "    for idx in tqdm(active_indices, desc=\"Examples\"):\n",
    "        item = train_ds_list[idx]\n",
    "        Q_inf, A_gt, A_ans = item[\"problem\"], item[\"solution\"], item[\"answer\"]\n",
    "\n",
    "        # --- encode & retrieve as before ---\n",
    "        q_emb = encoder.encode([Q_inf], detach=False).squeeze(0)\n",
    "        demo_pool = [d for j, d in enumerate(raw_demos) if j != idx]\n",
    "        demo_questions = [d[\"problem\"] for d in demo_pool]\n",
    "        demo_embs = encoder.batched_encode(demo_questions, batch_size=16, detach=False)\n",
    "        top_k_inds, sims = rc.retrieve_top_k_cosine(q_emb, demo_embs, k=min(K, len(demo_questions)))\n",
    "        \n",
    "        top_k_inds_adj = [i if i < idx else i + 1 for i in top_k_inds]\n",
    "        print(\"-------Question---------\")\n",
    "        print(Q_inf)\n",
    "        print(f\"\\nðŸ§  Inference Index {idx}\")\n",
    "        print(f\"ðŸ” Top-K Indices: {top_k_inds_adj}\")\n",
    "        top_k_inds, sims = rc.retrieve_sample_k_cosine(q_emb, demo_embs, k=min(K, len(demo_questions)), tau=0.01)\n",
    "        top_k_inds_adj = [i.item() if i.item() < idx else i.item() + 1 for i in top_k_inds]\n",
    "        print(f\"â— Sampled Indices: {top_k_inds_adj}\")\n",
    "        \n",
    "        \n",
    "\n",
    "        selected = [(raw_demos[i], i) for i in top_k_inds_adj]\n",
    "        # Remember the demo_q's that was selected here. \n",
    "        \n",
    "        # --- sample responses & compute mean reward ---\n",
    "        responses_nested = sample_responses_per_demo(\n",
    "            demo_tuples=[(d[0][\"problem\"], d[0][\"solution\"], d[0][\"answer\"],d[1]) for d in selected],\n",
    "            Q_inf=Q_inf,\n",
    "            icl_model=icl_model,\n",
    "            num_samples=NUM_SAMPLES_PER_DEMO,\n",
    "            parallel=True\n",
    "        )\n",
    "        print(\"Responses_nested:\", responses_nested)\n",
    "        rewards = []\n",
    "        print(\"Responses: \", responses_nested)\n",
    "        for i, responses in enumerate(responses_nested):\n",
    "            reward = compute_demo_accuracy(responses, A_ans)\n",
    "            rewards.append(reward)\n",
    "            # print(f\"    Demo {i} | Reward: {reward:.2f}\")\n",
    "        \n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(DEVICE)\n",
    "        print(\"Rewards tensor:\", rewards)\n",
    "        print(\"Sims tensor:\", sims)\n",
    "        loss = grpo_step(\n",
    "            rewards,\n",
    "            sims,\n",
    "            q_emb,\n",
    "            demo_embs,\n",
    "            optimizer\n",
    "        )\n",
    "        scheduler.step()\n",
    "\n",
    "        mean_r = rewards.mean().item()\n",
    "        epoch_rewards[idx] = mean_r\n",
    "\n",
    "        # decide whether to keep for next epoch\n",
    "        if mean_r <= 0.75:\n",
    "            next_active.append(idx)\n",
    "\n",
    "        print(f\"âœ…  idx={idx} | Mean Reward: {mean_r:.4f} | Loss: {loss:.4f}\")\n",
    "\n",
    "    # record this epochâ€™s full reward vector (with Nones)\n",
    "    reward_history.append(epoch_rewards)\n",
    "\n",
    "    dropped = len(active_indices) - len(next_active)\n",
    "    print(f\"Epoch {step+1}: dropped {dropped} examples (mean_râ€‰>â€‰0.75).\")\n",
    "    active_indices = next_active\n",
    "\n",
    "    if not active_indices:\n",
    "        print(\"All examples have convergedâ€”stopping early.\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70185e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- reshape rewards ---\n",
    "# epoch_wide_rewards  -> shape (num_epochs, num_questions)\n",
    "epoch_wide_rewards = [[item for item in rewards] for rewards in reward_history]\n",
    "reward_matrix = np.array(epoch_wide_rewards)       # (E, Q)\n",
    "num_epochs, num_qs = reward_matrix.shape\n",
    "\n",
    "# --- plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(1, num_epochs + 1)\n",
    "\n",
    "for q in range(num_qs):\n",
    "    plt.plot(x, reward_matrix[:, q], label=f\"Q{q}\", alpha=0.8)\n",
    "\n",
    "plt.title(\"Per-question reward trajectory\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean reward\")\n",
    "plt.xticks(x)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# put the legend outside so the graph isnâ€™t cluttered\n",
    "plt.legend(\n",
    "    bbox_to_anchor=(1.05, 1), loc=\"upper left\",\n",
    "    ncol=2, fontsize=\"small\", frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebaeea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive-sloping lines: 4\n",
      "Negative-sloping lines: 5\n",
      "Flat / insufficient data: 31\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1.  Build a (E, Q) array from reward_history\n",
    "# -------------------------------------------------\n",
    "reward_matrix = np.asarray([[v for v in row] for row in reward_history],\n",
    "                           dtype=object)         # keep Nones intact\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2.  Convert to float, using NaN for missing values\n",
    "# -------------------------------------------------\n",
    "rm_float = np.full_like(reward_matrix, np.nan, dtype=float)\n",
    "for i in range(rm_float.shape[0]):\n",
    "    for j in range(rm_float.shape[1]):\n",
    "        v = reward_matrix[i, j]\n",
    "        rm_float[i, j] = np.nan if v is None else float(v)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3.  Count slopes\n",
    "# -------------------------------------------------\n",
    "pos, neg, flat = 0, 0, 0\n",
    "\n",
    "for q in range(rm_float.shape[1]):\n",
    "    col = rm_float[:, q]\n",
    "    idx = np.where(~np.isnan(col))[0]            # finite rows\n",
    "    if len(idx) < 2:                             # need â‰¥2 points\n",
    "        flat += 1\n",
    "        continue\n",
    "\n",
    "    first, last = col[idx[0]], col[idx[-1]]\n",
    "    if last > first:\n",
    "        pos += 1\n",
    "    elif last < first:\n",
    "        neg += 1\n",
    "    else:\n",
    "        flat += 1\n",
    "\n",
    "print(f\"Positive-sloping lines: {pos}\")\n",
    "print(f\"Negative-sloping lines: {neg}\")\n",
    "print(f\"Flat / insufficient data: {flat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7be05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Top-K Indices: [78, 79, 211]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:   5%|â–Œ         | 1/20 [00:01<00:22,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['48 + (48/2) = 48 + 24 = 72', '48 + (48 / 2) = 48 + 24 = 72', '48 + (48 Ã· 2) = 48 + 24 = 72', '48 + (48/2) = 48 + 24 = 72', '48 + (48 Ã· 2) = 48 + 24 = 72'], ['48 + 24 = 72', '72', '48 + 48/2 = 48 + 24 = 72', '48 + (48/2) = 48 + 24 = 72', '144'], ['48 + 24 = 72', '48 + (48/2) = 48 + 24 = 72', '48 + 24 = 72', '72', '72']]\n",
      "0.9333333333333333\n",
      "ðŸ” Top-K Indices: [63, 119, 81]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  10%|â–ˆ         | 2/20 [00:02<00:23,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10', '10', '10', '10', '10'], ['10', '10', '10', '10', '10'], ['10', '10', '10', '10', '10']]\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [13, 82, 11]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  15%|â–ˆâ–Œ        | 3/20 [00:03<00:22,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['55', '55', '55', '55', '55'], ['25', '53', '53', '50', '53'], ['55', '70', '55', '55', '55']]\n",
      "0.9333333333333333\n",
      "ðŸ” Top-K Indices: [130, 136, 229]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  20%|â–ˆâ–ˆ        | 4/20 [00:05<00:19,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['48', '54', '48', '48', '54'], ['60', '60', '60', '60', '60'], ['48', '48', '48', '48', '48']]\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [63, 119, 140]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:19,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['312', '312', '312', '312', '312'], ['312', '312', '312', '312', '312'], ['312', '312', '312', '312', '312']]\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [135, 105, 41]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:07<00:19,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['130', '110', '110', 'Total yellow flowers = 10  \\nPurple flowers = 80% more than yellow = 10 + 0.80 * 10 = 10 + 8 = 18  \\nTotal yellow and purple = 10 + 18 = 28  \\nGreen flowers = 25% of yellow and purple = 0.25 * 28 = 7  \\nTotal flowers = yellow + purple + green = 10 + 18 + 7 = 35', 'Total yellow flowers = 10  \\nPurple flowers = 80% more than yellow = 10 + 0.80 * 10 = 10 + 8 = 18  \\nTotal yellow and purple = 10 + 18 = 28  \\nGreen flowers = 25% of yellow and purple = 0.25 * 28 = 7  \\nTotal flowers = yellow + purple + green = 10 + 18 + 7 = 35'], ['Yellow: 10\\nPurple: 80% more than yellow = 10 * 1.8 = 18\\nYellow + purple: 10 + 18 = 28\\nGreen: 25% of yellow + purple = 0.25 * 28 = 7\\nTotal flowers: 10 + 18 + 7 = 35', 'Yellow = 10  \\nPurple = 80% more than yellow = 10 + 0.8 * 10 = 10 + 8 = 18  \\nTotal yellow and purple = 10 + 18 = 28  \\nGreen = 25% of yellow and purple = 0.25 * 28 = 7  \\nTotal flowers = yellow + purple + green = 10 + 18 + 7 = 35', 'Yellow: 10  \\nPurple: 80% more than yellow = 10 + 0.80 * 10 = 10 + 8 = 18  \\nTotal yellow and purple: 10 + 18 = 28  \\nGreen: 25% as many as yellow and purple combined = 0.25 * 28 = 7  \\nTotal flowers: 10 + 18 + 7 = 35', 'Yellow: 10  \\nPurple: 80% more than yellow = 10 + 0.8 * 10 = 10 + 8 = 18  \\nTotal yellow and purple: 10 + 18 = 28  \\nGreen: 25% of yellow and purple = 0.25 * 28 = 7  \\nTotal flowers: 10 + 18 + 7 = 35', 'Yellow flowers: 10  \\nPurple flowers: 80% more than yellow = 10 * 1.8 = 18  \\nTotal yellow and purple: 10 + 18 = 28  \\nGreen flowers: 25% of yellow and purple = 0.25 * 28 = 7  \\nTotal flowers: 10 + 18 + 7 = 35'], ['250', '250', '250', '250', '125']]\n",
      "0.4666666666666667\n",
      "ðŸ” Top-K Indices: [8, 93, 140]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:18,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['48', '48', '48', '48', '48'], ['48', '48', '48', '48', '48'], ['48', '48', '48', '48', '48']]\n",
      "1.0\n",
      "ðŸ” Top-K Indices: [91, 18, 17]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:16,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['16', '16', '8', '8', '8'], ['8', '10', '8', '16', '16'], ['8', '16', '16', '16', '16']]\n",
      "0.5333333333333333\n",
      "ðŸ” Top-K Indices: [85, 94, 173]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:15,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['41', '41', '41', '61', '61'], ['$41', '$41', '$41', '87', '$41'], ['87', '87', '$41', '$41', '$41']]\n",
      "0.6666666666666666\n",
      "ðŸ” Top-K Indices: [119, 18, 63]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['$495', '$405', '$405', '$585', '$405'], ['$270', '90', '$405', '$270', '10*1.5*18=270  \\n270*5=1350'], ['$495', '$405', '$495', '$495', '540']]\n",
      "0.06666666666666667\n",
      "ðŸ” Top-K Indices: [223, 42, 142]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:15<00:13,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4', '42', '42', '422', '1'], ['423.5', '422', '423.5', '1', '423'], ['423.5', '423.5', '423.5', '423.5', '423.5']]\n",
      "0.13333333333333333\n",
      "ðŸ” Top-K Indices: [105, 85, 49]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:16<00:11,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2', '2', '7', \"4 lawns x $15 = $60; total money saved = $95 - $15 (change) = $80; money from mowing = $60; remaining money for shoveling = $80 - $60 = $20; shoveling earns $7 each; number of driveways = $20 / $7 â‰ˆ 2.86; since he can't shovel a fraction of a driveway, he must have shoveled 2 driveways.\", \"4 lawns x $15 = $60  \\nTotal money saved before buying shoes = $95 + $15 (change) = $110  \\nTotal money from mowing lawns = $60  \\nMoney from shoveling driveways = $110 - $60 = $50  \\nNumber of driveways shoveled = $50 / $7 â‰ˆ 7.14  \\nSince he can't shovel a fraction of a driveway, he shovels 7 driveways\"], ['4', '4', '4', '4', '4'], ['3', '5', '4', '4', '10']]\n",
      "0.2\n",
      "ðŸ” Top-K Indices: [5, 211, 82]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:18<00:10,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['55', '80', '55', '55', '55'], ['60 + (60/2 - 5) = 60 + (30 - 5) = 60 + 25 = 85', '60 + (1/2 * 60 - 5) = 60 + (30 - 5) = 60 + 25 = 85', '60 + ( (1/2) * 60 - 5 ) = 60 + (30 - 5) = 60 + 25 = 85', '60 + (60/2 - 5) = 60 + (30 - 5) = 60 + 25 = 85', '60 + ( (1/2) * 60 - 5 ) = 60 + (30 - 5) = 60 + 25 = 85'], ['75', '75', '60 + (1/2 * 60 - 5) = 60 + (30 - 5) = 60 + 25 = 85', '75', '75']]\n",
      "0.4\n",
      "ðŸ” Top-K Indices: [241, 48, 117]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:19<00:08,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['$30', '$30', '$40', '$30', '$40'], ['$34', '$10 + $5 + $20 = 35', '$30', '$10 + $5 + $20 = 35', '$40'], ['$20', '$26', '$36', '$34', '$34']]\n",
      "0.13333333333333333\n",
      "ðŸ” Top-K Indices: [2, 3, 130]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:20<00:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3', '120 / 8 = 15 (sets of 8 pages)\\n15 * 20 = 300 minutes\\n300 / 60 = 5 hours', '120 / 8 = 15 (number of 20-minute segments needed)\\n15 * 20 minutes = 300 minutes\\n300 / 60 = 5 hours', '120 / 8 = 15 (number of reading sessions needed)\\n15 * 20 = 300 minutes\\n300 / 60 = 5 hours', '120 / 8 = 15  \\n15 * 20 = 300 minutes  \\n300 / 60 = 5 hours'], ['3', '20/8 = 2.5 minutes per page  \\n120 * 2.5 = 300 minutes  \\n300 / 60 = 5 hours', '3', '3', '20 minutes / 8 pages = 2.5 minutes per page  \\n120 pages Ã— 2.5 minutes = 300 minutes  \\n300 minutes Ã· 60 = 5 hours'], ['3', '3', '3', '3', '3']]\n",
      "0.4\n",
      "ðŸ” Top-K Indices: [81, 63, 197]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:23<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['6000', '15000', '15000', '37500', '35000'], ['30000', '$90000', 'Profit per DVD = 2.5 * 6 - 6 = 15 - 6 = 9  \\nNumber of DVDs sold in 20 weeks = 500 DVDs/day * 5 days/week * 20 weeks = 500 * 5 * 20 = 50,000  \\nTotal profit = 50,000 * 9 = 450,000', '75000', 'Profit per DVD = 6 * 2.5 - 6 = 15 - 6 = 9  \\nNumber of DVDs sold in 20 weeks = 500 * 5 * 20 = 50,000  \\nTotal profit = 50,000 * 9 = 450,000'], ['$15000', '$132,000', '$22,500', '$15,000', '$7,500']]\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [66, 145, 81]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:25<00:05,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1000', '1000', '$1000', '1000', '$1000'], ['200', \"Mike's share = (2/5) * 2500 = 1000  \\nMoney left after buying the shirt = 1000 - 200 = 800\", \"Mike's share = (2 / (2 + 5)) * 2500 = (2 / 7) * 2500 â‰ˆ 714.2857  \\nMoney Mike has after buying the shirt = 714.2857 - 200 â‰ˆ 514.2857  \\nFinal answer: 514\", \"Mike's share = (2/5) Ã— 2500 = 1000  \\nRemaining after buying the shirt = 1000 - 200 = 800  \\nAnswer: 800\", \"Mike's share is (2/7) of total profit, and Johnson's share is (5/7) of total profit.\\n\\nJohnson's share = $2500 = (5/7) of total profit  \\nTotal profit = $2500 * (7/5) = $2500 * 1.4 = $3500\\n\\nMike's share = (2/7) of total profit = (2/7) * $3500 = $1000\\n\\nAfter buying the shirt for $200, Mike has:  \\n$1000 - $200 = $800\\n\\n800\"], ['1000', '1000', '714.29', '1000', '1000']]\n",
      "0.2\n",
      "ðŸ” Top-K Indices: [82, 156, 182]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:27<00:03,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['47', '53', '73', '53', '33'], ['49', '55', '61', '55', '49'], ['53', '49', '26 - 4 = 22 pink hard hats remaining\\nJohn takes away 6 pink hard hats and twice as many green hard hats as the pink hard hats he took, so green hard hats taken by John = 2 * 6 = 12\\nRemaining pink hard hats = 22 - 6 = 16\\nRemaining green hard hats = 15 - 12 = 3\\nRemaining yellow hard hats = 24 (none taken)\\nTotal remaining hard hats = 16 + 3 + 24 = 43', '26 + 15 + 24 = 65\\nCarl takes away 4 pink hard hats: remaining pink = 26 - 4 = 22\\nJohn takes away 6 pink hard hats: remaining pink = 22 - 6 = 16\\nJohn takes away twice as many green hard hats as pink hard hats he removed: 2 * 6 = 12 green hard hats\\nRemaining green hard hats = 15 - 12 = 3\\nTotal remaining hard hats = pink + green + yellow = 16 + 3 + 24 = 43', \"26 - 4 = 22 (pink hard hats remaining after Carl's removal)  \\nJohn takes away 6 pink hard hats, leaving 22 - 6 = 16 pink hard hats in the truck  \\nJohn takes away twice as many green hard hats as the pink hard hats he removed: 2 * 6 = 12 green hard hats  \\nGreen hard hats remaining: 15 - 12 = 3  \\nTotal hard hats remaining: pink (16) + green (3) + yellow (24) = 16 + 3 + 24 = 43\"]]\n",
      "0.2\n",
      "ðŸ” Top-K Indices: [18, 94, 15]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:28<00:01,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9', '9', '9', '10', '9'], ['9', '9', '9', '9', '9'], ['9', '9', '9', '9', '9']]\n",
      "0.0\n",
      "ðŸ” Top-K Indices: [18, 119, 15]\n",
      "[INFO] Launching 15 parallel inference tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10', '10', '8', '9', '16'], ['8', '8', '8', '8', '8'], ['16', '16', '16', '16', '20 miles each way, so 40 miles per day for 5 days: 40*5=200 miles  \\nWeekend ride: 200 miles  \\nTotal miles: 200+200=400 miles  \\nTime = Distance / Speed = 400 / 25 = 16 hours']]\n",
      "0.4\n",
      "\n",
      "ðŸ“Š  Baseline accuracy on GSM8K_to_infer: 38.333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0.  Imports & config â€“ nothing here should clash with yours\n",
    "# ------------------------------------------------------------\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from mathbert_encoder import MathBERTEncoder\n",
    "import retriever_cosine as rc\n",
    "# from import retrieve_top_k_cosine, retrieve_sample_k_cosine\n",
    "from response_sampler import sample_responses_per_demo\n",
    "from reward_aggregator import compute_demo_accuracy\n",
    "from icl_model_wrapper import OpenAIICLModel\n",
    "from grpo_optimizer import grpo_step\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "\n",
    "reload(rc)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "K       = 3                # demos per query\n",
    "NUM_SAMPLES = 5             # model completions per query\n",
    "TEMPERATURE = 0.7           # keep same as training loop\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.  Initialise encoder **in eval mode** (weights frozen)\n",
    "# ------------------------------------------------------------\n",
    "encoder.eval()                                   # no grads!\n",
    "\n",
    "icl_model = OpenAIICLModel(api_key=API_KEY,\n",
    "                           model_name=\"gpt-4.1-nano\",\n",
    "                           temperature=TEMPERATURE)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.  Load/define the inference set\n",
    "#     If you already saved a slice elsewhere, just load it.\n",
    "# ------------------------------------------------------------\n",
    "gsm8k_data = load_dataset(\"gsm8k\", \"main\")[\"train\"].select(range(256))  # slice first 200 examples\n",
    "gsm8k_to_infer = load_dataset(\"gsm8k\", \"main\")[\"train\"] \\\n",
    "                     .select(range(20))          # â¬… change as needed\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3.  Evaluation loop\n",
    "# ------------------------------------------------------------\n",
    "total, correct = 0, 0\n",
    "all_losses     = []          # optional â€“ to compare prompt quality\n",
    "\n",
    "for idx in tqdm(range(len(gsm8k_to_infer)), desc=\"Baseline eval\"):\n",
    "    item       = gsm8k_to_infer[idx]\n",
    "    Q_inf, A_gt = item[\"question\"], item[\"answer\"]\n",
    "\n",
    "    # Build demo pool (everything except current query)\n",
    "    demos = [(d[\"question\"], d[\"answer\"])\n",
    "             for j, d in enumerate(gsm8k_data) if j != idx]\n",
    "\n",
    "    # Encode query + candidate demos\n",
    "    with torch.no_grad():\n",
    "        q_emb     = encoder.encode([Q_inf], detach=True).squeeze(0)\n",
    "        demo_embs = encoder.encode([q for (q, _) in demos], detach=True)\n",
    "\n",
    "    # ------- ORIGINAL cosine retrieval -------------------------\n",
    "    top_k, _ = rc.retrieve_top_k_cosine(\n",
    "        q_emb, demo_embs, k=min(K, len(demos))\n",
    "    )\n",
    "    print(f\"ðŸ” Top-K Indices: {top_k}\")\n",
    "    selected_demos = [demos[i] for i in top_k]          # length = 2\n",
    "\n",
    "    # ------- Run the ICL model --------------------------------\n",
    "    responses_nested = sample_responses_per_demo(\n",
    "        demo_tuples = selected_demos,\n",
    "        Q_inf       = Q_inf,\n",
    "        icl_model   = icl_model,\n",
    "        num_samples = NUM_SAMPLES,\n",
    "        parallel=True\n",
    "    )\n",
    "    print(responses_nested)\n",
    "    flat_responses = [r for demo_resps in responses_nested for r in demo_resps]\n",
    "    acc = compute_demo_accuracy(flat_responses, A_gt)\n",
    "    print(acc) \n",
    "    correct += acc\n",
    "    total   += 1\n",
    "\n",
    "baseline_acc = correct / total\n",
    "print(f\"\\nðŸ“Š  Baseline accuracy on GSM8K_to_infer: {baseline_acc:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./53k_q3_1024_demos_0.7_temp_40_max_steps_temp_mathbert/tokenizer_config.json',\n",
       " './53k_q3_1024_demos_0.7_temp_40_max_steps_temp_mathbert/special_tokens_map.json',\n",
       " './53k_q3_1024_demos_0.7_temp_40_max_steps_temp_mathbert/vocab.txt',\n",
       " './53k_q3_1024_demos_0.7_temp_40_max_steps_temp_mathbert/added_tokens.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the updated MathBERT model\n",
    "save_path = \"./10k_q4_128_demos_0.1_temp_20_max_steps_on_MATH500_mathbert\"  # your save directory\n",
    "encoder.model.save_pretrained(save_path)\n",
    "encoder.tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# LOADING\n",
    "\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# model = BertModel.from_pretrained(\"./updated_mathbert\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"./updated_mathbert\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
